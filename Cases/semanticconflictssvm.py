# -*- coding: utf-8 -*-
"""SemanticConflictsSVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I8i-wf3WkDn7Ij-hZVgPpmzFP0i3MOcN
"""

import os
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from typing import List, Tuple

# Funções modulares:

def load_java_file(filepath: str) -> str:
    """Lê um arquivo .java e retorna seu conteúdo."""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

def load_java_files_from_directory(dir_path: str) -> Tuple[List[str], List[str]]:
    """
    Varre um diretório e retorna:
      - lista de conteúdos de todos os .java encontrados
      - lista de caminhos correspondentes
    """
    java_contents, file_paths = [], []
    for root, _, files in os.walk(dir_path):
        for file in files:
            if file.endswith('.java'):
                full_path = os.path.join(root, file)
                java_contents.append(load_java_file(full_path))
                file_paths.append(full_path)
    return java_contents, file_paths

def preprocess_data(code_samples: List[str]) -> List[str]:
    """Remove comentários Java de linha e bloco."""
    cleaned = []
    for code in code_samples:
        lines = code.splitlines()
        no_comments, in_block = [], False
        for line in lines:
            stripped = line.strip()
            if stripped.startswith("/*"):
                in_block = True
            if not in_block and not stripped.startswith("//"):
                no_comments.append(line)
            if stripped.endswith("*/"):
                in_block = False
        cleaned.append("\n".join(no_comments))
    return cleaned

def train_svm_model(codes: List[str], labels: List[int]) -> Pipeline:
    """Treina pipeline TF-IDF + SVC."""
    pipeline = Pipeline([
        ('tfidf', TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")),
        ('clf', SVC(kernel='linear', probability=True))
    ])
    pipeline.fit(codes, labels)
    return pipeline

def save_model(model: Pipeline, filepath: str):
    """Salva o modelo treinado."""
    joblib.dump(model, filepath)

def load_model(filepath: str) -> Pipeline:
    """Carrega o modelo salvo."""
    return joblib.load(filepath)

def predict_conflicts(model: Pipeline, code_samples: List[str]) -> List[Tuple[int, float]]:
    """Retorna (predição, probabilidade) por amostra de código."""
    preds = model.predict(code_samples)
    probs = model.predict_proba(code_samples).max(axis=1)
    return list(zip(preds, probs))


# Pastas contendo exemplos positivos (conflito) e negativos (sem conflito)
positive_dir = '/content/drive/MyDrive/CasesDrive'
negative_dir = '/content/drive/MyDrive/negative_examples'

# Carrega e rotula
pos_codes, pos_paths = load_java_files_from_directory(positive_dir)
neg_codes, neg_paths = load_java_files_from_directory(negative_dir)

if not pos_codes or not neg_codes:
    raise RuntimeError("Garanta que ambos os diretórios (positivo e negativo) contenham .java.")

all_codes  = pos_codes + neg_codes
all_paths  = pos_paths + neg_paths
all_labels = [1]*len(pos_codes) + [0]*len(neg_codes)

# Pré-processa e treina
cleaned = preprocess_data(all_codes)
model   = train_svm_model(cleaned, all_labels)
save_model(model, '/content/svm_conflict_model.joblib')

# Predição nos mesmos exemplos (ou em novos se desejar trocar all_codes)
loaded_model = load_model('/content/svm_conflict_model.joblib')
preds = predict_conflicts(loaded_model, cleaned)

# Exibe resultados
for path, (pred, prob) in zip(all_paths, preds):
    label_str = "CONFLITO" if pred == 1 else "SEM CONFLITO"
    print(f"Arquivo: {path}\nPredição: {label_str} (prob.={prob:.2f})\n")

import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.metrics import classification_report, confusion_matrix
from typing import List, Tuple

def load_java_files_from_directory(dir_path: str) -> Tuple[List[str], List[str]]:
    java_contents, file_paths = [], []
    for root, _, files in os.walk(dir_path):
        for file in files:
            if file.endswith('.java'):
                full_path = os.path.join(root, file)
                with open(full_path, 'r', encoding='utf-8') as f:
                    java_contents.append(f.read())
                file_paths.append(full_path)
    return java_contents, file_paths

def preprocess_data(code_samples: List[str]) -> List[str]:
    cleaned = []
    for code in code_samples:
        lines = code.splitlines()
        no_comments, in_block = [], False
        for line in lines:
            stripped = line.strip()
            if stripped.startswith("/*"):
                in_block = True
            if not in_block and not stripped.startswith("//"):
                no_comments.append(line)
            if stripped.endswith("*/"):
                in_block = False
        cleaned.append("\n".join(no_comments))
    return cleaned

# Monte o Drive antes de rodar:
# from google.colab import drive
# drive.mount('/content/drive')

# Diretórios
positive_dir = '/content/drive/MyDrive/CasesDrive'
negative_dir = '/content/drive/MyDrive/negative_examples'

# Carrega positivos e negativos
pos_codes, pos_paths = load_java_files_from_directory(positive_dir)
neg_codes, neg_paths = load_java_files_from_directory(negative_dir)
if not pos_codes or not neg_codes:
    raise RuntimeError("Ambos os diretórios (positivo e negativo) devem conter ao menos um .java")

all_codes  = pos_codes + neg_codes
all_labels = [1]*len(pos_codes) + [0]*len(neg_codes)

# Pré-processa
cleaned = preprocess_data(all_codes)

# Pipeline com unigramas + bigramas
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(token_pattern=r"(?u)\b\w+\b",
                              ngram_range=(1,2),
                              min_df=1)),
    ('clf', SVC(kernel='linear', probability=True))
])

# Validação cruzada estratificada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
preds_cv = cross_val_predict(pipeline, cleaned, all_labels, cv=cv)

# Métricas
print("=== Relatório de Classificação ===")
print(classification_report(all_labels, preds_cv, target_names=["Sem Conflito","Conflito"]))
print("=== Matriz de Confusão ===")
print(confusion_matrix(all_labels, preds_cv))